{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmdhpy.gmdh import Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions1(test, predicted):\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.2)  # Set the style and font scale\n",
    "\n",
    "    plt.figure(figsize=(12, 6), dpi=150)  # Set the figure size and DPI\n",
    "\n",
    "    # Plotting the actual values\n",
    "    sns.lineplot(data=test, color='red', linewidth=2, label='Real SPI')\n",
    "\n",
    "    # Plotting the predicted values\n",
    "    sns.lineplot(data=predicted, color='blue', linewidth=2, label='Predicted SPI')\n",
    "\n",
    "    # Customizing the plot\n",
    "    plt.title('SPI Value Prediction', fontsize=16)\n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.ylabel('SPI', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Adding eye-catching elements\n",
    "    plt.fill_between(range(len(test)), test, predicted, color='gray', alpha=0.2)\n",
    "    plt.axvline(x=50, color='green', linestyle='--', linewidth=1.5)\n",
    "    plt.text(50, max(test), 'Prediction Start', color='green', fontsize=12)\n",
    "\n",
    "    # Adjusting the plot appearance\n",
    "    sns.despine()\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions2(test, predicted):\n",
    "    plt.figure(figsize=(12, 6), dpi=150)  # Set the figure size and DPI\n",
    "\n",
    "    # Plotting the actual values\n",
    "    plt.plot(test, color='red', linewidth=1.5, label='Real SPI')\n",
    "\n",
    "    # Plotting the predicted values\n",
    "    plt.plot(predicted, color='blue', linewidth=1.5, label='Predicted SPI')\n",
    "\n",
    "    # Customizing the plot\n",
    "    plt.title('SPI Value Prediction', fontsize=16)\n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.ylabel('SPI', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Adding eye-catching elements\n",
    "    plt.fill_between(range(len(test)), test, predicted, color='gray', alpha=0.2)\n",
    "    plt.axvline(x=50, color='green', linestyle='--', linewidth=1.5)\n",
    "    plt.text(50, max(test), 'Prediction Start', color='green', fontsize=12)\n",
    "\n",
    "    # Adjusting the plot appearance\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Some functions to help out with\n",
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real SPI')\n",
    "    plt.plot(predicted, color='blue',label='Predicted SPI')\n",
    "    plt.title('SPI Value Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('SPI')\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.show()\n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "    print(\"The MSE is {}\".format(mean_squared_error(test, predicted)))\n",
    "    print(\"The MAE is {}\".format(mean_absolute_error(test, predicted)))\n",
    "    print(\"The R2_Score is {}\".format(r2_score(test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cf10cf27420eb383b93b15c0895139ea96c0ed3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# First, we get the data\n",
    "dataset = pd.read_csv(r\"wavelet_kesinga.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['Approximation','D 2', 'D 3', 'D 6']].values  # Select the desired features\n",
    "y = dataset.iloc[:, 0].values  # Target variable (SPI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate variables for the combined datasets\n",
    "training_set = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "test_set = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Checking for missing values\n",
    "# training_set = dataset[:'2016'].iloc[:,1:2].values\n",
    "# test_set = dataset['2017':].iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf5a9463d58e73852d2b70be9611e8cf1f4166fd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # We have chosen 'High' attribute for prices. Let's see what it looks like\n",
    "# dataset[\"High\"][:'2016'].plot(figsize=(16,4),legend=True)\n",
    "# dataset[\"High\"]['2017':].plot(figsize=(16,4),legend=True)\n",
    "# plt.legend(['Training set (Before 2017)','Test set (2017 and beyond)'])\n",
    "# plt.title('CSCO stock price')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Scaling the training set\n",
    "# sc = MinMaxScaler(feature_range=(0,1))\n",
    "# training_set_scaled = sc.fit_transform(training_set)\n",
    "# # print(training_set_scaled.shape)\n",
    "# print(training_set.shape)\n",
    "# print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = []\n",
    "# y_train = []\n",
    "# for i in range(60,training_set.shape[0]):\n",
    "#     X_train.append(training_set[i-20:i,0])\n",
    "#     y_train.append(training_set[i,0])\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmdh = Regressor(ref_functions=('cubic','quadratic','linear','linear_cov'),\n",
    "                      criterion_type='validate',\n",
    "                      criterion_minimum_width=5,\n",
    "                      stop_train_epsilon_condition=0.00001,\n",
    "                      layer_err_criterion='top',\n",
    "                      l2=0.5,\n",
    "                      verbose=1,\n",
    "                      n_jobs='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now to get the test set ready in a similar way as the training set.\n",
    "# # The following has been done so first 60 entires of test set have 60 previous values which is impossible to get unless we take the whole \n",
    "# # 'High' attribute data for processing\n",
    "# # dataset_total = pd.concat((dataset[\"High\"][:'2016'],dataset[\"High\"]['2017':]),axis=0)\n",
    "# inputs = X_train\n",
    "# # print(inputs.shape)\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# print(inputs.shape)\n",
    "\n",
    "# # print(inputs.shape)\n",
    "# # inputs  = sc.transform(inputs)\n",
    "# # print(inputs.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing X_test and predicting the prices\n",
    "# X_test = []\n",
    "# y_test = []\n",
    "# for i in range(60,inputs.shape[0]):\n",
    "#     X_test.append(inputs[i-20:i,0])\n",
    "#     y_test.append(inputs[i,0])\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1]))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmdh.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = gmdh.predict(X_test)\n",
    "print(final_predictions.shape)\n",
    "# predicted_stock_price = regressor.predict(X_test)\n",
    "# predicted_stock_price.reshape(-1,1)\n",
    "# predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_test,final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions1(y_test,final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions2(y_test,final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rmse(y_test,final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test, final_predictions = list(y_test),list(final_predictions)\n",
    "# gmdh.score(y_test, predicted_stock_price)\n",
    "r2_score(y_test, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_evaluation_metrics(y_observed, y_predicted):\n",
    "     # Convert to NumPy arrays if they are lists\n",
    "    if isinstance(y_observed, list):\n",
    "        y_observed = np.array(y_observed)\n",
    "    if isinstance(y_predicted, list):\n",
    "        y_predicted = np.array(y_predicted)\n",
    "        \n",
    "    metrics = {}\n",
    "\n",
    "    # Calculate ME (Mean Error)\n",
    "    metrics['ME'] = np.mean(y_observed - y_predicted)\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    metrics['MAE'] = mean_absolute_error(y_observed, y_predicted)\n",
    "\n",
    "    # Calculate MSE (Mean Squared Error)\n",
    "    metrics['MSE'] = mean_squared_error(y_observed, y_predicted)\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    metrics['RMSE'] = np.sqrt(metrics['MSE'])\n",
    "\n",
    "    # Calculate NRMSE (Normalized Root Mean Squared Error)\n",
    "    metrics['NRMSE'] = metrics['RMSE'] / (np.max(y_observed) - np.min(y_observed))\n",
    "\n",
    "    # Calculate PBIAS (Percent Bias)\n",
    "    metrics['PBIAS'] = np.mean(100 * (y_observed - y_predicted) / np.mean(y_observed))\n",
    "\n",
    "    # Calculate RSR (Root Mean Square Ratio)\n",
    "    metrics['RSR'] = metrics['RMSE'] / np.std(y_observed)\n",
    "\n",
    "    # Calculate rSD (Ratio of the Standard Deviation)\n",
    "    metrics['rSD'] = np.std(y_observed - y_predicted) / np.std(y_observed)\n",
    "\n",
    "    # Calculate NSE (Nash-Sutcliffe Efficiency)\n",
    "    metrics['NSE'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((y_observed - np.mean(y_observed)) ** 2))\n",
    "\n",
    "    # Calculate mNSE (Modified Nash-Sutcliffe Efficiency)\n",
    "    metrics['mNSE'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((y_observed - np.mean(y_observed)) ** 2))\n",
    "\n",
    "    # Calculate rNSE (Relative Nash-Sutcliffe Efficiency)\n",
    "    metrics['rNSE'] = metrics['NSE'] / np.var(y_observed)\n",
    "\n",
    "    # Calculate d (Index of Agreement)\n",
    "    metrics['d'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((np.abs(y_predicted - np.mean(y_observed)) +\n",
    "                                                                       np.abs(y_observed - np.mean(y_observed))) ** 2))\n",
    "\n",
    "    # Calculate md (Modified d Index)\n",
    "    metrics['md'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((np.abs(y_predicted - np.mean(y_observed)) +\n",
    "                                                                         np.abs(y_observed - np.mean(y_observed))) ** 2))\n",
    "\n",
    "    # Calculate rd (Relative d Index)\n",
    "    metrics['rd'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((np.abs(y_predicted - np.mean(y_observed)) +\n",
    "                                                                         np.abs(y_observed - np.mean(y_observed))) ** 2))\n",
    "\n",
    "    # Calculate cp (Coefficient of Performance)\n",
    "    metrics['cp'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((np.abs(y_predicted - y_observed.mean()) +\n",
    "                                                                         np.abs(y_observed - y_observed.mean())) ** 2))\n",
    "\n",
    "    # Calculate r (Index of Agreement)\n",
    "    metrics['r'] = 1 - (np.sum((y_observed - y_predicted) ** 2) / np.sum((np.abs(y_predicted - y_observed.mean()) +\n",
    "                                                                        np.abs(y_observed - y_observed.mean())) ** 2))\n",
    "\n",
    "    # Calculate R2 (Coefficient of Determination)\n",
    "    metrics['R2'] = r2_score(y_observed, y_predicted)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = calculate_evaluation_metrics(y_test, final_predictions)\n",
    "print(evaluation_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=11\n",
    "print(y_test[k],final_predictions[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fccfb866a2b4c702e0b2742f7c0289512d713d1b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Since LSTMs store long term memory state, we create a data structure with 60 timesteps and 1 output\n",
    "# # So for each element of training set, we have 60 previous training set elements \n",
    "# X_train = []\n",
    "# y_train = []\n",
    "# for i in range(60,2769):\n",
    "#     X_train.append(training_set_scaled[i-60:i,0])\n",
    "#     y_train.append(training_set_scaled[i,0])\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "637f699d3c4bde4b783de56ed4dd70a1bf59760d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df20eb7e8062dae0a3aff2182aa440faddd0017d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Second LSTM layer\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Third LSTM layer\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Fourth LSTM layer\n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.2))\n",
    "# The output layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n",
    "# Fitting to the training set\n",
    "regressor.fit(X_train,y_train,epochs=900,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "326fa85615622feb484cc4c848edeec6f7133913",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Now to get the test set ready in a similar way as the training set.\n",
    "# # The following has been done so forst 60 entires of test set have 60 previous values which is impossible to get unless we take the whole \n",
    "# # 'High' attribute data for processing\n",
    "# dataset_total = pd.concat((dataset[\"High\"][:'2016'],dataset[\"High\"]['2017':]),axis=0)\n",
    "# inputs = dataset_total[len(dataset_total)-len(test_set) - 60:].values\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# inputs  = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "435b8024814939ac4fbd372baa0cd8cfc78f80bc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Preparing X_test and predicting the prices\n",
    "# X_test = []\n",
    "# for i in range(60,311):\n",
    "#     X_test.append(inputs[i-60:i,0])\n",
    "# X_test = np.array(X_test)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_spi = regressor.predict(X_test)\n",
    "# predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "predicted_spi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b774a8e79e53eac89694cafef6b11aa99226b95f",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing the results for LSTM\n",
    "plot_predictions(y_test,predicted_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6f6db0b6e1f17ac63c06ce49856873d98ba5f00",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating our model\n",
    "return_rmse(y_test,predicted_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = calculate_evaluation_metrics(y_test, predicted_spi)\n",
    "print(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4cf704ab3cd091f63b7b9a1b9224a49f0913171"
   },
   "source": [
    "Truth be told. That's one awesome score. \n",
    "\n",
    "LSTM is not the only kind of unit that has taken the world of Deep Learning by a storm. We have **Gated Recurrent Units(GRU)**. It's not known, which is better: GRU or LSTM becuase they have comparable performances. GRUs are easier to train than LSTMs.\n",
    "\n",
    "## Gated Recurrent Units\n",
    "In simple words, the GRU unit does not have to use a memory unit to control the flow of information like the LSTM unit. It can directly makes use of the all hidden states without any control. GRUs have fewer parameters and thus may train a bit faster or need less data to generalize. But, with large data, the LSTMs with higher expressiveness may lead to better results.\n",
    "\n",
    "They are almost similar to LSTMs except that they have two gates: reset gate and update gate. Reset gate determines how to combine new input to previous memory and update gate determines how much of the previous state to keep. Update gate in GRU is what input gate and forget gate were in LSTM. We don't have the second non linearity in GRU before calculating the outpu, .neither they have the output gate.\n",
    "\n",
    "Source: [Quora](https://www.quora.com/Whats-the-difference-between-LSTM-and-GRU-Why-are-GRU-efficient-to-train)\n",
    "\n",
    "<img src=\"https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/11/GRU.png?x31195\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9b616c5112d707d16cc4b277007e286cffd58f6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# The GRU architecture\n",
    "regressorGRU = Sequential()\n",
    "# First GRU layer with Dropout regularisation\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "# Second GRU layer\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "# Third GRU layer\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "# Fourth GRU layer\n",
    "regressorGRU.add(GRU(units=50, activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "# The output layer\n",
    "regressorGRU.add(Dense(units=1))\n",
    "# Compiling the RNN\n",
    "regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
    "# Fitting to the training set\n",
    "regressorGRU.fit(X_train,y_train,epochs=1200,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "98628386f141545aa77d70f48478ac82bd9c1608"
   },
   "source": [
    "The current version version uses a dense GRU network with 100 units as opposed to the GRU network with 50 units in previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f20ca021ea3ce05f6c6a98db93775f1b2c9c022c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Preparing X_test and predicting the prices\n",
    "# X_test = []\n",
    "# for i in range(60,311):\n",
    "#     X_test.append(inputs[i-60:i,0])\n",
    "# X_test = np.array(X_test)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "GRU_predicted_spi = regressorGRU.predict(X_test)\n",
    "# GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)\n",
    "GRU_predicted_spi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da8e9fa28510aa03e7dd06d5070d7b16e05ebb6e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the results for GRU\n",
    "plot_predictions(y_test,GRU_predicted_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23aec5ab1a717e3458c8d5cae68db0e7add091ae",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating GRU\n",
    "return_rmse(y_test,GRU_predicted_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = calculate_evaluation_metrics(y_test, GRU_predicted_spi)\n",
    "print(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
