{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ac0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all features: \t(0.09591836734693877,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin      \tmax      \n",
      "0  \t10    \t0.082449\t0.0591837\t0.0979592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \t5     \t0.0946939\t0.0836735\t0.106122 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  \t6     \t0.0973469\t0.077551 \t0.106122 \n",
      "Best Accuracy: \t0.10612244897959185\n",
      "Number of Features in Subset: \t3\n",
      "Individual: \t\t[0, 1, 1, 1, 0]\n",
      "Feature Subset\t: ['D 1', 'D 2', 'D 3']\n",
      "\n",
      "\n",
      "creating a new classifier with the result\n",
      "Accuracy with Feature Subset: \t0.10612244897959185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asitg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "import sys\n",
    "\n",
    "\n",
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))\n",
    "\n",
    "\n",
    "def getFitness(individual, X, y):\n",
    "    \"\"\"\n",
    "    Feature subset fitness function\n",
    "    \"\"\"\n",
    "\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(individual)) if individual[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "        return (avg(cross_val_score(clf, X_subset, y, cv=5)),)\n",
    "    else:\n",
    "        return(0,)\n",
    "\n",
    "\n",
    "def geneticAlgorithm(X, y, n_population, n_generation):\n",
    "    \"\"\"\n",
    "    Deap global variables\n",
    "    Initialize variables to use eaSimple\n",
    "    \"\"\"\n",
    "    # create individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    # create toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat,\n",
    "                     creator.Individual, toolbox.attr_bool, len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list,\n",
    "                     toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", getFitness, X=X, y=y)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # initialize parameters\n",
    "    pop = toolbox.population(n=n_population)\n",
    "    hof = tools.HallOfFame(n_population * n_generation)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # genetic algorithm\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2,\n",
    "                                   ngen=n_generation, stats=stats, halloffame=hof,\n",
    "                                   verbose=True)\n",
    "\n",
    "    # return hall of fame\n",
    "    return hof\n",
    "\n",
    "def bestIndividual(hof, X, y):\n",
    "    \"\"\"\n",
    "    Get the best individual\n",
    "    \"\"\"\n",
    "    maxAccuracy = 0.0\n",
    "    bestInd = None\n",
    "    bestHeader = None\n",
    "\n",
    "    for individual in hof:\n",
    "        accuracy = individual.fitness.values[0]\n",
    "        if accuracy > maxAccuracy:\n",
    "            maxAccuracy = accuracy\n",
    "            bestInd = individual\n",
    "            bestHeader = [list(X)[i] for i in range(len(individual)) if individual[i] == 1]\n",
    "\n",
    "    return maxAccuracy, bestInd, bestHeader\n",
    "\n",
    "\n",
    "\n",
    "def getArguments():\n",
    "    \"\"\"\n",
    "    Get argumments from command-line\n",
    "    If pass only dataframe path, pop and gen will be default\n",
    "    \"\"\"\n",
    "    dfPath = sys.argv[1]\n",
    "    if(len(sys.argv) == 4):\n",
    "        pop = int(sys.argv[2])\n",
    "        gen = int(sys.argv[3])\n",
    "    else:\n",
    "        pop = 10\n",
    "        gen = 2\n",
    "    return dfPath, pop, gen\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # get dataframe path, population number and generation number from command-line argument\n",
    "    dataframePath, n_pop, n_gen = getArguments()\n",
    "    # read dataframe from csv\n",
    "    df = pd.read_csv('wavelet_coefficients_coif4.csv')\n",
    "\n",
    "    # encode labels column to numbers\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.iloc[:, 0])  # Fit the label encoder on the first column\n",
    "    y = le.transform(df.iloc[:, 0])  # Transform the values in the first column\n",
    "    X = df.iloc[:, 1:]  # Select all columns except the first one as your features\n",
    "\n",
    "\n",
    "    # get accuracy with all features\n",
    "    individual = [1 for i in range(len(X.columns))]\n",
    "    print(\"Accuracy with all features: \\t\" +\n",
    "          str(getFitness(individual, X, y)) + \"\\n\")\n",
    "\n",
    "    # apply genetic algorithm\n",
    "    hof = geneticAlgorithm(X, y, n_pop, n_gen)\n",
    "\n",
    "    # select the best individual\n",
    "    accuracy, individual, header = bestIndividual(hof, X, y)\n",
    "    print('Best Accuracy: \\t' + str(accuracy))\n",
    "    print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "    print('Individual: \\t\\t' + str(individual))\n",
    "    print('Feature Subset\\t: ' + str(header))\n",
    "\n",
    "    print('\\n\\ncreating a new classifier with the result')\n",
    "\n",
    "    # read dataframe from csv one more time\n",
    "    df = pd.read_csv('wavelet_coefficients_coif4.csv')\n",
    "\n",
    "    # with feature subset\n",
    "    X = df[header]\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"Accuracy with Feature Subset: \\t\" + str(avg(scores)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ecfaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
